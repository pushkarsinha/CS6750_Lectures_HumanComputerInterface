1
00:00:00,000 --> 00:00:02,250
 In Don Norman's Design of Everyday Things,

2
00:00:02,250 --> 00:00:05,100
 he provides a different way of looking at the same information.

3
00:00:05,100 --> 00:00:09,795
 This diagram puts a greater emphasis on what the user is doing at each of these stages.

4
00:00:09,795 --> 00:00:11,460
 The user is setting a goal,

5
00:00:11,460 --> 00:00:12,960
 and then planning, and specifying,

6
00:00:12,960 --> 00:00:14,760
 and performing, and then perceiving,

7
00:00:14,760 --> 00:00:16,545
 and interpreting, and comparing.

8
00:00:16,545 --> 00:00:20,100
 This diagram also changes our terminology a bit and with good reason.

9
00:00:20,100 --> 00:00:24,045
 We see a bridge of execution and a bridge of evaluation.

10
00:00:24,045 --> 00:00:27,120
 The reason for that is these behaviors specifically

11
00:00:27,120 --> 00:00:31,190
 bridge the gulf between the goal and the world.

12
00:00:31,190 --> 00:00:34,790
 They're what the user has to do to make the world match their goal,

13
00:00:34,790 --> 00:00:38,150
 and then confirm that the world now does match their goal.

14
00:00:38,150 --> 00:00:41,270
 Norman uses these stages to introduce seven questions

15
00:00:41,270 --> 00:00:44,485
 that we should ask ourselves when we're designing interfaces.

16
00:00:44,485 --> 00:00:49,595
 First, how easily can one determine the function of the device?

17
00:00:49,595 --> 00:00:54,185
 In other words, how easily can one tell that this device can accomplish that goal?

18
00:00:54,185 --> 00:00:59,185
 Second, how easily can one tell what actions are possible to do with the device?

19
00:00:59,185 --> 00:01:02,720
 Third, how easily can the user determine the mapping from

20
00:01:02,720 --> 00:01:06,830
 their intent to the actual movements or actions they need to take with the device?

21
00:01:06,830 --> 00:01:09,080
 So, in planning to figuring out what they can

22
00:01:09,080 --> 00:01:12,200
 do with specifying to figuring out what they should do.

23
00:01:12,200 --> 00:01:14,825
 Then finally, how easily can the user actually

24
00:01:14,825 --> 00:01:18,365
 perform the physical movements associated with that plan?

25
00:01:18,365 --> 00:01:20,434
 After they've done these three stages,

26
00:01:20,434 --> 00:01:22,070
 something has happened in the world,

27
00:01:22,070 --> 00:01:25,300
 and they're ready to see if they can perceive what has changed.

28
00:01:25,300 --> 00:01:30,710
 So, then we ask, how easily can the user perceive or tell what state the system is in?

29
00:01:30,710 --> 00:01:33,830
 This is the raw information that they're getting out of the system.

30
00:01:33,830 --> 00:01:38,210
 Then how easily can they tell if the system is in the desired state,

31
00:01:38,210 --> 00:01:41,645
 or how easily can they interpret what they perceived?

32
00:01:41,645 --> 00:01:46,360
 Then finally, how easily can the user determine the mapping from state to interpretation?

33
00:01:46,360 --> 00:01:49,610
 In other words, how easily can the user compare what

34
00:01:49,610 --> 00:01:52,985
 they interpreted as happening to what they wanted to happen?

35
00:01:52,985 --> 00:01:55,430
 You'll notice that these match our stages from earlier.

36
00:01:55,430 --> 00:01:58,265
 Norman also makes it even more clear by describing this

37
00:01:58,265 --> 00:02:01,325
 specifically in terms of what the user is thinking.

38
00:02:01,325 --> 00:02:02,660
 The user starts by thinking,

39
00:02:02,660 --> 00:02:04,195
 "What do I want to do?"

40
00:02:04,195 --> 00:02:07,175
 Then they consider, "What are the alternatives for accomplishing it?"

41
00:02:07,175 --> 00:02:11,125
 Then they specify, "What can I do to actually perform one of those alternatives?"

42
00:02:11,125 --> 00:02:13,120
 Then they ask, "How do I do that?"

43
00:02:13,120 --> 00:02:16,355
 Once they've done it, they ask, "What happened?

44
00:02:16,355 --> 00:02:19,385
 What does that mean? Is that okay?"

45
00:02:19,385 --> 00:02:21,460
 I like this phrasing because it makes the distinction

46
00:02:21,460 --> 00:02:24,055
 between interpreting and comparing a little easier.

47
00:02:24,055 --> 00:02:26,845
 Interpreting is just about understanding what happened.

48
00:02:26,845 --> 00:02:30,970
 Comparing involves going back to the original goal that the user had.

49
00:02:30,970 --> 00:02:33,910
 Norman also further articulates this by breaking the process

50
00:02:33,910 --> 00:02:37,460
 into phases that span both execution and evaluation.

51
00:02:37,460 --> 00:02:40,030
 Closest to the world, he has the visceral phase which is

52
00:02:40,030 --> 00:02:43,150
 the actual physical activity or the raw perceptions.

53
00:02:43,150 --> 00:02:45,250
 Above that, he has the behavioral layer,

54
00:02:45,250 --> 00:02:47,470
 which is where we're actually specifying what behaviors to

55
00:02:47,470 --> 00:02:50,315
 do or interpreting the outcome of those behaviors.

56
00:02:50,315 --> 00:02:52,950
 Then at the top level, there's a reflective phase,

57
00:02:52,950 --> 00:02:56,135
 which is thinking about the problem and planning our solution,

58
00:02:56,135 --> 00:02:58,840
 or comparing the results to our original goal.

59
00:02:58,840 --> 00:03:00,930
 If we change his vocabulary a little bit,

60
00:03:00,930 --> 00:03:04,465
 we might describe this lowest level as raw reaction,

61
00:03:04,465 --> 00:03:06,855
 the middle level as deliberation,

62
00:03:06,855 --> 00:03:09,240
 and the top level as metacognition,

63
00:03:09,240 --> 00:03:10,380
 thinking about the goal,

64
00:03:10,380 --> 00:03:12,110
 thinking about the problem solving process,

65
00:03:12,110 --> 00:03:15,065
 thinking about what we did and what happened.

66
00:03:15,065 --> 00:03:17,930
 If we rewrite these phases with this vocabulary,

67
00:03:17,930 --> 00:03:22,115
 we start to get at a diagram you might recognize if you've taken knowledge-based AI.

68
00:03:22,115 --> 00:03:22,115
 If you haven't, here's a little teaser for what you'll see if you do.

