1
00:00:00,000 --> 00:00:02,760
 Cognitive task analysis is not really a single method,

2
00:00:02,760 --> 00:00:04,860
 but it's more of a type of method for

3
00:00:04,860 --> 00:00:07,725
 approaching the evaluation of how people complete tasks.

4
00:00:07,725 --> 00:00:10,530
 Performing a cognitive task analysis involves a number of

5
00:00:10,530 --> 00:00:12,300
 different techniques and methods that we'll discuss

6
00:00:12,300 --> 00:00:14,340
 more when we discuss the design lifecycle.

7
00:00:14,340 --> 00:00:16,470
 For right now though, we're interested in

8
00:00:16,470 --> 00:00:18,780
 what kinds of information we're trying to gather,

9
00:00:18,780 --> 00:00:20,385
 not how we're gathering it.

10
00:00:20,385 --> 00:00:23,010
 Cognitive task analyses are especially concerned with

11
00:00:23,010 --> 00:00:26,595
 understanding the underlying thought processing performing a task,

12
00:00:26,595 --> 00:00:30,070
 not just what we can see but specifically what we can't see.

13
00:00:30,070 --> 00:00:31,950
 There are a lot of different methods for performing

14
00:00:31,950 --> 00:00:36,000
 cognitive task analyses but most methods follow a particular common sequence.

15
00:00:36,000 --> 00:00:39,090
 First, we want to collect some preliminary knowledge.

16
00:00:39,090 --> 00:00:42,529
 While we as interface designers don't need to become experts in a field,

17
00:00:42,529 --> 00:00:44,610
 we need a good bit of familiarity with it.

18
00:00:44,610 --> 00:00:47,690
 So, we might observe people performing the task for example.

19
00:00:47,690 --> 00:00:51,394
 In navigation, we might just watch someone driving and using a GPS.

20
00:00:51,394 --> 00:00:54,770
 Our second step is to identify knowledge representations.

21
00:00:54,770 --> 00:00:59,750
 In other words, what kinds of things does a user need to know to complete their task?

22
00:00:59,750 --> 00:01:02,915
 Note that we're not yet concerned with the actual knowledge they have,

23
00:01:02,915 --> 00:01:05,905
 only the types or structures of the knowledge that they have.

24
00:01:05,905 --> 00:01:07,700
 For example, we want to know,

25
00:01:07,700 --> 00:01:11,180
 does this task involves a series of steps to do in a certain order?

26
00:01:11,180 --> 00:01:14,790
 Does it involve a collection of tasks to check off in any order?

27
00:01:14,790 --> 00:01:17,455
 Does it involve a web of knowledge to memorize?

28
00:01:17,455 --> 00:01:19,060
 For navigation, for example,

29
00:01:19,060 --> 00:01:21,800
 we would identify that the structure of the knowledge is a sequence of

30
00:01:21,800 --> 00:01:25,700
 actions and order as well as knowledge of things to monitor as we go.

31
00:01:25,700 --> 00:01:27,080
 In the third stage,

32
00:01:27,080 --> 00:01:30,230
 we actually want to populate those knowledge representations.

33
00:01:30,230 --> 00:01:34,010
 This is the stage where we start to recognize what the user actually knows.

34
00:01:34,010 --> 00:01:35,510
 With navigation for example,

35
00:01:35,510 --> 00:01:37,010
 they know to start the GPS,

36
00:01:37,010 --> 00:01:39,230
 to enter an address and to obey the turns while

37
00:01:39,230 --> 00:01:41,800
 monitoring traffic and speed and things like that.

38
00:01:41,800 --> 00:01:45,860
 During this stage, we identify all the specific actions they take,

39
00:01:45,860 --> 00:01:48,740
 the knowledge they must have in mind to take those actions,

40
00:01:48,740 --> 00:01:51,260
 the interruptions that can change their thought processes,

41
00:01:51,260 --> 00:01:55,010
 the equipment involved and the sensory experience of the user.

42
00:01:55,010 --> 00:01:58,280
 We do this by applying focused knowledge elicitation methods.

43
00:01:58,280 --> 00:02:00,680
 In other words, we get users to tell us what's

44
00:02:00,680 --> 00:02:03,440
 going on in their heads or what's going on in their environment or

45
00:02:03,440 --> 00:02:06,470
 sometimes we do things that help us understand parts of the task that

46
00:02:06,470 --> 00:02:09,500
 the user isn't even themselves aware of.

47
00:02:09,500 --> 00:02:12,830
 Then we analyze and verify the data we acquired.

48
00:02:12,830 --> 00:02:14,930
 Part of that is just confirming with the people we

49
00:02:14,930 --> 00:02:16,865
 observe that our understanding is correct.

50
00:02:16,865 --> 00:02:19,130
 We might watch them do something and infer it for

51
00:02:19,130 --> 00:02:21,685
 one reason when in reality it's for a very different reason.

52
00:02:21,685 --> 00:02:24,380
 So, we want to present to our users our results and make sure

53
00:02:24,380 --> 00:02:27,235
 that they agree with our understanding of their task.

54
00:02:27,235 --> 00:02:29,990
 Then we attempt to formalize it into structures that can be

55
00:02:29,990 --> 00:02:33,610
 compared and summarized across multiple data gathering methods.

56
00:02:33,610 --> 00:02:37,130
 Finally, we format our results for the intended application.

57
00:02:37,130 --> 00:02:39,320
 We need to take those results and format them in

58
00:02:39,320 --> 00:02:41,805
 a way that's useful for interface design.

59
00:02:41,805 --> 00:02:44,660
 We want to develop models that show what the user was thinking,

60
00:02:44,660 --> 00:02:49,580
 feeling and remembering at any given time and make those relationships really explicit.

61
00:02:49,580 --> 00:02:52,190
 The result might look something like this.

62
00:02:52,190 --> 00:02:56,150
 Here we see a very high level model of the process of driving to a destination.

63
00:02:56,150 --> 00:02:58,520
 What's interesting to note is that these tasks in

64
00:02:58,520 --> 00:03:01,715
 the middle are highly cognitive rather than observable.

65
00:03:01,715 --> 00:03:05,660
 If I had no knowledge about driving and I sat in the passenger seat watching the driver,

66
00:03:05,660 --> 00:03:08,210
 I might never know that they're monitoring their route progress or

67
00:03:08,210 --> 00:03:10,910
 keeping an eye on their dashboard for how much fuel they have left.

68
00:03:10,910 --> 00:03:14,150
 If you have kids, you may have experienced this personally actually.

69
00:03:14,150 --> 00:03:15,500
 Two kids sitting in the backseat,

70
00:03:15,500 --> 00:03:16,880
 mommy or daddy are just sitting in

71
00:03:16,880 --> 00:03:19,370
 the driver seat just like they're sitting in the passenger seat.

72
00:03:19,370 --> 00:03:21,230
 They don't have a full understanding of the fact that you have

73
00:03:21,230 --> 00:03:23,075
 a much higher cognitive load and you're

74
00:03:23,075 --> 00:03:25,645
 doing a lot more things while you're driving then they are.

75
00:03:25,645 --> 00:03:29,270
 That's because what you're doing is not observable. It's all in your head.

76
00:03:29,270 --> 00:03:30,800
 So, to get at these things,

77
00:03:30,800 --> 00:03:34,220
 I might have the user to think out loud about what they're doing, while they're doing it.

78
00:03:34,220 --> 00:03:37,465
 I might have them tell me what they're thinking while they're driving the car.

79
00:03:37,465 --> 00:03:37,465
 That would give me some insights into these cognitive elements of the task.

