1
00:00:00,190 --> 00:00:02,480
 Here would be my answers to this exercise.

2
00:00:02,480 --> 00:00:05,536
 These are a little bit more objective than some of our exercises in the past.

3
00:00:05,536 --> 00:00:09,950
 First, if it does not require any actual users, predictive evaluation is the only

4
00:00:09,950 --> 00:00:13,878
 evaluation we can do without involving users in the evaluation process.

5
00:00:13,878 --> 00:00:16,490
 That's both its biggest strength and its biggest weakness.

6
00:00:16,490 --> 00:00:18,466
 For identifying provable advantages,

7
00:00:18,466 --> 00:00:22,418
 only empirical evaluation can reliably generate generalizable conclusions,

8
00:00:22,418 --> 00:00:26,870
 generalizable advantages, because it's the only one who does it numerically.

9
00:00:26,870 --> 00:00:29,434
 As far as informing ongoing design decisions is concerned,

10
00:00:29,434 --> 00:00:32,618
 that's definitely the case for qualitative and predictive evaluation.

11
00:00:32,618 --> 00:00:36,151
 I've left it unmarked for empirical evaluation simply because we usually do

12
00:00:36,151 --> 00:00:38,269
 this towards the end of our design life cycle,

13
00:00:38,269 --> 00:00:41,387
 although we also know that the design life cycle never really ends.

14
00:00:41,387 --> 00:00:42,165
 So eventually,

15
00:00:42,165 --> 00:00:45,620
 empirical evaluation could be used to inform ongoing design decisions.

16
00:00:45,620 --> 00:00:49,500
 It's just not involved in the earlier cycles though the design life cycle.

17
00:00:49,500 --> 00:00:52,152
 As far as investing the participant's thought process, again,

18
00:00:52,152 --> 00:00:54,105
 empirical evaluation doesn't really do that.

19
00:00:54,105 --> 00:00:56,713
 It only accesses participants performance numerically.

20
00:00:56,713 --> 00:01:00,370
 Qualitative evaluation definitely does this, because it actually asks users

21
00:01:00,370 --> 00:01:03,080
 to think out lout and describe their thought process.

22
00:01:03,080 --> 00:01:06,310
 And really, predictive evaluation tries to investigate the participant's thought

23
00:01:06,310 --> 00:01:10,400
 process, just in a lower overhead, or lower cost kind of way.

24
00:01:10,400 --> 00:01:13,490
 It does so by having experts in usability design simulate

25
00:01:13,490 --> 00:01:15,070
 the participant's thought process, and

26
00:01:15,070 --> 00:01:18,230
 comment on it from the perspective of some preset heuristics.

27
00:01:18,230 --> 00:01:21,760
 Similar to how only empirical evaluation can identify provable advantages,

28
00:01:21,760 --> 00:01:24,590
 it's also the only one that can provide generalizable conclusions,

29
00:01:24,590 --> 00:01:26,510
 again because it uses numbers.

30
00:01:26,510 --> 00:01:27,700
 And finally, qualitative and

31
00:01:27,700 --> 00:01:30,960
 empirical evaluations both draw conclusions from actual participants.

32
00:01:30,960 --> 00:01:34,680
 This is the inverse of predictive evaluations, lack of requirement for

33
00:01:34,680 --> 00:01:34,680
 actual users.

