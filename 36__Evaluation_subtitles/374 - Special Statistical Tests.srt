1
00:00:00,000 --> 00:00:03,930
 Chi-squared tests and t-tests are probably the most commonly used tests in HCI.

2
00:00:03,930 --> 00:00:07,950
 However, there are some assumptions embedded in the ones we just looked at.

3
00:00:07,950 --> 00:00:12,030
 First, notice that we only ever had two levels to our independent variable.

4
00:00:12,030 --> 00:00:15,030
 We were only ever comparing online and traditional students.

5
00:00:15,030 --> 00:00:18,240
 For your work, that might mean only comparing two different interfaces.

6
00:00:18,240 --> 00:00:21,825
 What if we wanted to test three? How can we do that?

7
00:00:21,825 --> 00:00:23,810
 Imagine for example, I wanted to test

8
00:00:23,810 --> 00:00:26,785
 these two classes against a third class or flipped class.

9
00:00:26,785 --> 00:00:29,300
 Here we'd be testing the online section versus

10
00:00:29,300 --> 00:00:32,825
 the traditional section versus the flipped section, how would we do that?

11
00:00:32,825 --> 00:00:35,660
 You might be tempted to just test them in a pairwise fashion,

12
00:00:35,660 --> 00:00:37,175
 test online versus traditional,

13
00:00:37,175 --> 00:00:39,740
 traditional verse flipped and online verse flipped.

14
00:00:39,740 --> 00:00:43,040
 You use that to try to uncover any differences between pairs.

15
00:00:43,040 --> 00:00:44,945
 That's called repeated testing,

16
00:00:44,945 --> 00:00:49,325
 and the problem, is that it raises the likelihood of a type one error.

17
00:00:49,325 --> 00:00:51,890
 A type one error is also called a false positive,

18
00:00:51,890 --> 00:00:55,175
 and it's where we falsely reject the null hypothesis.

19
00:00:55,175 --> 00:00:57,590
 In other words, we falsely say that we have

20
00:00:57,590 --> 00:01:00,380
 enough data to conclude the alternative hypothesis.

21
00:01:00,380 --> 00:01:02,600
 Here that would mean, falsely concluding

22
00:01:02,600 --> 00:01:05,065
 that there is a difference when there isn't actually a difference.

23
00:01:05,065 --> 00:01:08,210
 The reason repeated testing raises likelihood of this,

24
00:01:08,210 --> 00:01:11,870
 is that remember we said that we reject the null hypothesis if there's

25
00:01:11,870 --> 00:01:16,040
 generally less than a five percent chance it could have occurred by random chance.

26
00:01:16,040 --> 00:01:18,010
 But if you do three different tests,

27
00:01:18,010 --> 00:01:20,180
 you raise the likelihood of one of them turning

28
00:01:20,180 --> 00:01:22,535
 up conclusive even though it really isn't.

29
00:01:22,535 --> 00:01:24,200
 Think of it like playing the lottery.

30
00:01:24,200 --> 00:01:27,860
 If I say you have a one in 20 chance of winning and you play 20 times,

31
00:01:27,860 --> 00:01:29,305
 you'll still win once.

32
00:01:29,305 --> 00:01:32,555
 That's because your overall odds of winning increased.

33
00:01:32,555 --> 00:01:38,080
 Performing multiple tests, raises our overall likelihood of finding a false positive.

34
00:01:38,080 --> 00:01:39,640
 So instead, what we need,

35
00:01:39,640 --> 00:01:43,835
 is a single test that can compare against all these different treatments at once.

36
00:01:43,835 --> 00:01:46,340
 Now fortunately, for ordinal or nominal data,

37
00:01:46,340 --> 00:01:48,485
 it's actually just the same test.

38
00:01:48,485 --> 00:01:53,070
 A chi-squared test can handle more than just two levels of our independent variable.

39
00:01:53,070 --> 00:01:55,100
 Our alternative tests change a little bit,

40
00:01:55,100 --> 00:01:56,935
 if we're dealing with more than two levels.

41
00:01:56,935 --> 00:02:02,030
 The weakness here, is if we do a Chi-squared test on all three of these levels at once,

42
00:02:02,030 --> 00:02:06,185
 all it will tell us is if there's any difference between any of the levels.

43
00:02:06,185 --> 00:02:08,255
 It doesn't tell us where the difference is.

44
00:02:08,255 --> 00:02:10,920
 So, if this chi-squared test shows that there is a difference,

45
00:02:10,920 --> 00:02:12,355
 we don't have any way of knowing,

46
00:02:12,355 --> 00:02:14,600
 is it the difference between the online and traditional,

47
00:02:14,600 --> 00:02:16,775
 online and flipped, traditional and flipped,

48
00:02:16,775 --> 00:02:19,040
 or is it a case where the flipped is different

49
00:02:19,040 --> 00:02:21,520
 from both the online and traditional or something like that.

50
00:02:21,520 --> 00:02:22,690
 So, generally what we do,

51
00:02:22,690 --> 00:02:25,835
 is we do an overall chi-squared tests on all of the levels,

52
00:02:25,835 --> 00:02:28,310
 and then we can follow up if that first test was

53
00:02:28,310 --> 00:02:31,765
 successful with a pairwise comparison between the conditions.

54
00:02:31,765 --> 00:02:34,370
 In that case, for basically concluding that we know there's

55
00:02:34,370 --> 00:02:36,830
 a difference before we actually do the repeated testing.

56
00:02:36,830 --> 00:02:40,370
 So, the overall odds of finding a false positive aren't changing.

57
00:02:40,370 --> 00:02:42,755
 For interval and ratio data though,

58
00:02:42,755 --> 00:02:44,735
 we need to use a different test altogether.

59
00:02:44,735 --> 00:02:48,670
 This test is called an analysis of variance or ANOVA.

60
00:02:48,670 --> 00:02:50,090
 A one-way ANOVA test,

61
00:02:50,090 --> 00:02:52,940
 let's us compare between three or more groups simultaneously.

62
00:02:52,940 --> 00:02:56,960
 Here, that means we could test between all three of our classes at the same time.

63
00:02:56,960 --> 00:03:00,505
 For you that can mean guessing between three or four interfaces at the same time.

64
00:03:00,505 --> 00:03:03,390
 With a two-way ANOVA, we could actually take this a step further.

65
00:03:03,390 --> 00:03:06,410
 We could have two dimensions of independent variables,

66
00:03:06,410 --> 00:03:08,780
 we could test online traditional and flipped

67
00:03:08,780 --> 00:03:11,510
 against upper class mean versus lower-class mean.

68
00:03:11,510 --> 00:03:13,400
 We could actually get it differences like,

69
00:03:13,400 --> 00:03:16,940
 do freshmen do better at online but sophomores do better in traditional.

70
00:03:16,940 --> 00:03:20,420
 The weakness though, is the same as the weakness with the chi-squared test,

71
00:03:20,420 --> 00:03:24,080
 and analysis of variance will tell us if there are differences,

72
00:03:24,080 --> 00:03:26,845
 but it won't tell us where the differences are.

73
00:03:26,845 --> 00:03:30,140
 Our approach to that is the same as it was with the chi-squared test as well.

74
00:03:30,140 --> 00:03:33,440
 If the analysis of variance indicates there's an overall difference,

75
00:03:33,440 --> 00:03:36,865
 then we can follow up with pairwise t-tests.

76
00:03:36,865 --> 00:03:39,440
 Notice though, there's still one assumption that's been

77
00:03:39,440 --> 00:03:42,005
 embedded in every single analysis we've talked about.

78
00:03:42,005 --> 00:03:45,610
 Our independent variables have always been categorical,

79
00:03:45,610 --> 00:03:48,280
 that's generally true for most of the tests we're going to do.

80
00:03:48,280 --> 00:03:50,450
 If we're testing one interface against another,

81
00:03:50,450 --> 00:03:52,295
 then those are our two categories.

82
00:03:52,295 --> 00:03:54,830
 If we're testing one body of people against another,

83
00:03:54,830 --> 00:03:56,470
 then those are our two categories.

84
00:03:56,470 --> 00:03:59,090
 So, this isn't really a weakness or a challenge,

85
00:03:59,090 --> 00:04:00,470
 but there are cases where we want

86
00:04:00,470 --> 00:04:03,140
 our independent variable to be something non-categorical.

87
00:04:03,140 --> 00:04:04,610
 Mostly that happens when we want

88
00:04:04,610 --> 00:04:07,885
 our independent variable to be some interval or ratio data.

89
00:04:07,885 --> 00:04:13,340
 So, imagine for example I wanted to see if GPA was a good predictor of course grade.

90
00:04:13,340 --> 00:04:16,010
 GPA though is generally considered interval data,

91
00:04:16,010 --> 00:04:19,340
 we might consider it ratio data but it's usually discussed as interval data.

92
00:04:19,340 --> 00:04:22,610
 We could do this by breaking GPA down into categories.

93
00:04:22,610 --> 00:04:27,290
 Instead of this, we could average the course grades for anyone with a GPA from 3.5-4,

94
00:04:27,290 --> 00:04:28,910
 3-3.5, and so on.

95
00:04:28,910 --> 00:04:31,130
 Or we could leave the GPA is interval data,

96
00:04:31,130 --> 00:04:32,890
 and just do a direct analysis.

97
00:04:32,890 --> 00:04:35,600
 Generally, here we'd be doing a regression or

98
00:04:35,600 --> 00:04:38,290
 we would see how well one variable predicts another.

99
00:04:38,290 --> 00:04:39,765
 Most of our regressions are linear,

100
00:04:39,765 --> 00:04:41,450
 but we could also do a logistic regression,

101
00:04:41,450 --> 00:04:43,655
 a polynomial regression, and lots more.

102
00:04:43,655 --> 00:04:46,580
 Again, I'm getting outside the scope of our class.

103
00:04:46,580 --> 00:04:50,120
 Here, our null hypothesis is that the variables are unrelated,

104
00:04:50,120 --> 00:04:53,300
 and our alternative hypothesis is that they are related.

105
00:04:53,300 --> 00:04:56,305
 So, we need evidence that they're related before assuming that they are.

106
00:04:56,305 --> 00:04:58,370
 Here things get a little bit more complex as well,

107
00:04:58,370 --> 00:05:00,830
 because we're not quite as emphatic about how we

108
00:05:00,830 --> 00:05:04,145
 reject our null hypothesis and accept our alternative hypothesis.

109
00:05:04,145 --> 00:05:07,495
 Usually with regressions, we describe how well the two fit.

110
00:05:07,495 --> 00:05:08,680
 They might fit very well,

111
00:05:08,680 --> 00:05:11,015
 somewhat well, not well at all, and so on.

112
00:05:11,015 --> 00:05:14,675
 Before we move on, there's one last type of data I'd like to talk about,

113
00:05:14,675 --> 00:05:16,250
 and that's binomial data.

114
00:05:16,250 --> 00:05:20,480
 Binomial data is data with only two possible outcomes, like a coin flip.

115
00:05:20,480 --> 00:05:23,650
 For us we might have outcomes like success in a class.

116
00:05:23,650 --> 00:05:25,820
 In HCI, we might be curious which of

117
00:05:25,820 --> 00:05:29,945
 multiple interfaces allows users to succeeded a task with greater frequency.

118
00:05:29,945 --> 00:05:33,275
 Notice there that, success and failure are binary,

119
00:05:33,275 --> 00:05:36,055
 and that's what makes this binomial data.

120
00:05:36,055 --> 00:05:37,390
 What can be tricky here,

121
00:05:37,390 --> 00:05:39,470
 is that our data actually looks continuous,

122
00:05:39,470 --> 00:05:42,245
 it looks just like straightforward continuous ratio data.

123
00:05:42,245 --> 00:05:46,095
 Here we might say online students succeed 94.9 percent of the time,

124
00:05:46,095 --> 00:05:49,100
 in traditional students succeed 92.1 percent of the time,

125
00:05:49,100 --> 00:05:52,075
 and we might be tempted just to do a straightforward t-test on that.

126
00:05:52,075 --> 00:05:53,520
 But if you try to do the math,

127
00:05:53,520 --> 00:05:55,260
 you'll quickly find that it doesn't work.

128
00:05:55,260 --> 00:05:57,820
 A t-test requires a standard deviation,

129
00:05:57,820 --> 00:06:00,290
 and if every single student is either a one or a zero,

130
00:06:00,290 --> 00:06:01,580
 a success or a failure,

131
00:06:01,580 --> 00:06:04,625
 then you don't really have a standard deviation in the same way.

132
00:06:04,625 --> 00:06:07,160
 So instead, we have a specific tests that we use for

133
00:06:07,160 --> 00:06:09,805
 binomial data called a binomial test.

134
00:06:09,805 --> 00:06:11,935
 With a two sample binomial test,

135
00:06:11,935 --> 00:06:14,000
 we compare two different sets of trials,

136
00:06:14,000 --> 00:06:16,130
 each with a certain number of successes.

137
00:06:16,130 --> 00:06:17,750
 So, we can answer questions like;

138
00:06:17,750 --> 00:06:20,720
 does one lead to a greater ratio of successes than the other?

139
00:06:20,720 --> 00:06:24,590
 Alternatively, we can also do a one-sample binomial test.

140
00:06:24,590 --> 00:06:29,970
 That's where we compare only one set of trials to some arbitrary number. So, for example.

141
00:06:29,970 --> 00:06:32,780
 If we wanted to prove that a coin was unbalanced,

142
00:06:32,780 --> 00:06:37,490
 we would use a one-sample binomial test comparing it to a ratio of 50 percent.

143
00:06:37,490 --> 00:06:40,250
 You'll know that you want to use binomial data,

144
00:06:40,250 --> 00:06:44,255
 if the individual observations you're getting out of users are binary.

145
00:06:44,255 --> 00:06:47,540
 If you're only concerned with whether they succeeded or failed on

146
00:06:47,540 --> 00:06:49,790
 a particular task and if your data is

147
00:06:49,790 --> 00:06:52,510
 just a bunch of instances of successes and failures,

148
00:06:52,510 --> 00:06:54,255
 then you're using binomial data.

149
00:06:54,255 --> 00:06:56,900
 If the data you're getting out of your users is more complex

150
00:06:56,900 --> 00:06:59,585
 like multiple categories or continuous observations,

151
00:06:59,585 --> 00:07:01,910
 then you're probably looking at using a chi-squared test or

152
00:07:01,910 --> 00:07:04,400
 a t-test or any of the ones we talked about before.

153
00:07:04,400 --> 00:07:07,010
 Now, we've gone through a lot of tests and we've gone through them very quickly,

154
00:07:07,010 --> 00:07:11,315
 but remember our goal is just for you to know what test to use and when.

155
00:07:11,315 --> 00:07:13,670
 Once you've identified the appropriate test,

156
00:07:13,670 --> 00:07:16,205
 looking at how to do it and actually putting the data in,

157
00:07:16,205 --> 00:07:16,205
 is usually a much simpler task.

