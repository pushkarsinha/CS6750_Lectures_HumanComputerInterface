1
00:00:00,000 --> 00:00:01,710
 When we talk about design principles,

2
00:00:01,710 --> 00:00:05,730
 we talked about several heuristics and guidelines we use in designing interfaces.

3
00:00:05,730 --> 00:00:08,970
 The first method for predictive evaluation is simply to hand

4
00:00:08,970 --> 00:00:12,345
 our interface and these guidelines to a few experts to evaluate.

5
00:00:12,345 --> 00:00:14,745
 This is called heuristic evaluation.

6
00:00:14,745 --> 00:00:17,880
 Each individual evaluator inspects the interface alone,

7
00:00:17,880 --> 00:00:21,315
 and identifies places where the interface violates some heuristic.

8
00:00:21,315 --> 00:00:23,300
 We might sit with an expert while they perform

9
00:00:23,300 --> 00:00:25,855
 the evaluation or they might generate our report.

10
00:00:25,855 --> 00:00:27,800
 Heuristics are useful because they give us

11
00:00:27,800 --> 00:00:31,445
 small snapshots into the way people might think about our interfaces.

12
00:00:31,445 --> 00:00:33,920
 If we take these heuristics to an extreme though,

13
00:00:33,920 --> 00:00:38,525
 we could go so far as to develop models of the way people think about our interfaces.

14
00:00:38,525 --> 00:00:40,340
 During our need-finding exercises,

15
00:00:40,340 --> 00:00:42,860
 we developed models of our users tasks.

16
00:00:42,860 --> 00:00:45,890
 In model-based evaluation, we take these models and

17
00:00:45,890 --> 00:00:49,025
 trace through it in the context of the interface that we designed.

18
00:00:49,025 --> 00:00:51,380
 So, let's use a Gomez model for example,

19
00:00:51,380 --> 00:00:55,100
 just we computed a Gomez model for what users data in some context,

20
00:00:55,100 --> 00:00:58,790
 we can also compute a Gomez model for what they will do in our new interface.

21
00:00:58,790 --> 00:01:01,880
 Then, we can compare these models side-by-side to see how

22
00:01:01,880 --> 00:01:05,650
 our interface changes the task and evaluate whether a deficiency.

23
00:01:05,650 --> 00:01:07,760
 So here, the classical way of disabling

24
00:01:07,760 --> 00:01:10,400
 an alarm was to use a keypad mountain near the door.

25
00:01:10,400 --> 00:01:13,100
 We could use this Gomez model to evaluate whether or not

26
00:01:13,100 --> 00:01:16,965
 the new keychain interface was actually more efficient than the keypad interface.

27
00:01:16,965 --> 00:01:19,610
 We can also use the profiles of users that we

28
00:01:19,610 --> 00:01:23,120
 developed to evaluate whether the new design meets each criteria.

29
00:01:23,120 --> 00:01:26,240
 For example, imagine if we identified this model as

30
00:01:26,240 --> 00:01:29,810
 applying to users with low motivation to use this interface?

31
00:01:29,810 --> 00:01:32,510
 Maybe it's people doing purchases that they have to do for work,

32
00:01:32,510 --> 00:01:34,370
 as opposed to just shopping at their leisure.

33
00:01:34,370 --> 00:01:36,950
 We can use that to inform our evaluation of

34
00:01:36,950 --> 00:01:39,905
 whether or not the interface relies on high user motivation.

35
00:01:39,905 --> 00:01:42,350
 If we find that the interface requires users to be

36
00:01:42,350 --> 00:01:44,960
 more personally driven or to keep more in working memory,

37
00:01:44,960 --> 00:01:47,210
 then we might find that the users will fail if

38
00:01:47,210 --> 00:01:49,520
 they don't have high motivation to use the interface,

39
00:01:49,520 --> 00:01:51,065
 and then we can revise it accordingly.

40
00:01:51,065 --> 00:01:54,010
 If we take model-based evaluation to an extreme though,

41
00:01:54,010 --> 00:01:57,350
 we can actually get to the point of simulation-based evaluation.

42
00:01:57,350 --> 00:01:59,030
 At that point, we might construct

43
00:01:59,030 --> 00:02:00,905
 an artificially intelligent agent that

44
00:02:00,905 --> 00:02:03,640
 interacts with our interface in the way that a human would.

45
00:02:03,640 --> 00:02:07,430
 Melody Ivory and Marti Hearst actually did some research on this back in 2001,

46
00:02:07,430 --> 00:02:11,950
 on The State of the Art In Automating Usability Evaluation of User Interfaces.

47
00:02:11,950 --> 00:02:14,090
 That seems like an amazing undertaking given

48
00:02:14,090 --> 00:02:16,910
 how flexible and varied user interfaces can actually be.

49
00:02:16,910 --> 00:02:18,875
 Can we really evaluate them automatically?

50
00:02:18,875 --> 00:02:23,270
 More recently, work has even been done to create even more human-like models of users,

51
00:02:23,270 --> 00:02:25,490
 like some work done by the Human-Centered Design Group

52
00:02:25,490 --> 00:02:28,040
 at the Institute for Information Technology in Germany.

53
00:02:28,040 --> 00:02:30,930
 Developing that agent is an enormous task on it's own,

54
00:02:30,930 --> 00:02:33,350
 but if we're working on a big long-term project like

55
00:02:33,350 --> 00:02:36,440
 Facebook or in a high-stakes environment like air traffic control,

56
00:02:36,440 --> 00:02:39,470
 having a simulation of a human that we can run hundreds of thousands of

57
00:02:39,470 --> 00:02:39,470
 times on different interface prototypes would be extremely useful.

