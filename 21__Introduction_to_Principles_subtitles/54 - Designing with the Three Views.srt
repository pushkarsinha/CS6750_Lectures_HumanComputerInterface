1
00:00:00,000 --> 00:00:03,240
 To better understand how we might use these three views of the user,

2
00:00:03,240 --> 00:00:06,180
 let's see how we might apply them to a design challenge.

3
00:00:06,180 --> 00:00:10,710
 So, here we have the address entry screen on Tesla's Model S. At the top,

4
00:00:10,710 --> 00:00:13,245
 we have the text box that the user is entering text into.

5
00:00:13,245 --> 00:00:14,895
 Below, we have some results.

6
00:00:14,895 --> 00:00:18,620
 At the bottom, we have the keyboard that they actually use to enter their text.

7
00:00:18,620 --> 00:00:21,680
 Let's imagine we're trying to redesign it such that the user can enter

8
00:00:21,680 --> 00:00:23,780
 the address of their target destination more

9
00:00:23,780 --> 00:00:26,285
 quickly so that they can get on with navigation.

10
00:00:26,285 --> 00:00:27,700
 With the processor model,

11
00:00:27,700 --> 00:00:30,360
 we're strictly looking at the user's observable behavior.

12
00:00:30,360 --> 00:00:33,980
 So, we might construct a controlled study where we bring participants in,

13
00:00:33,980 --> 00:00:36,739
 give them addresses to enter and different interfaces to use,

14
00:00:36,739 --> 00:00:38,945
 and time them on different versions.

15
00:00:38,945 --> 00:00:41,260
 Whichever interface has the fastest times

16
00:00:41,260 --> 00:00:43,385
 would be the interface we might want to go with.

17
00:00:43,385 --> 00:00:45,410
 There are some benefits to using this model.

18
00:00:45,410 --> 00:00:49,475
 One big one is that we might actually be able to use existing data for this.

19
00:00:49,475 --> 00:00:52,130
 If we assume that every time a user brings up the search bar,

20
00:00:52,130 --> 00:00:54,440
 they're going to input an address and navigate to,

21
00:00:54,440 --> 00:00:56,870
 we can look back and look how long does it usually

22
00:00:56,870 --> 00:01:00,565
 take from opening that search bar to access starting navigation.

23
00:01:00,565 --> 00:01:04,520
 We might be able to do that on an absolutely massive quantity of data.

24
00:01:04,520 --> 00:01:07,895
 Another benefit of this is it enables objective comparisons.

25
00:01:07,895 --> 00:01:10,385
 That means we can compare this text entry screen to

26
00:01:10,385 --> 00:01:13,940
 a voice system or some other way of inputting addresses to

27
00:01:13,940 --> 00:01:17,270
 understand how different interfaces entirely or different modes

28
00:01:17,270 --> 00:01:20,920
 of interaction entirely can have different efficiencies associated with them.

29
00:01:20,920 --> 00:01:24,080
 Most importantly, those comparisons are objective.

30
00:01:24,080 --> 00:01:27,605
 There's no real interpretation involved in saying that it takes an average

31
00:01:27,605 --> 00:01:32,015
 of 5.2 seconds to go from entering an address to starting navigation.

32
00:01:32,015 --> 00:01:33,635
 That's just a descriptive statistic.

33
00:01:33,635 --> 00:01:36,145
 However, there are some pretty major drawbacks as well.

34
00:01:36,145 --> 00:01:38,025
 When we're employing the processor model,

35
00:01:38,025 --> 00:01:41,240
 we don't see the reason for the differences that we observe.

36
00:01:41,240 --> 00:01:45,425
 We have no real basis to understand why one interface performs better than the other.

37
00:01:45,425 --> 00:01:48,230
 We also can't differentiate by expertise.

38
00:01:48,230 --> 00:01:50,360
 Usually, when we're using the processor model,

39
00:01:50,360 --> 00:01:51,830
 we're working with expert users,

40
00:01:51,830 --> 00:01:54,055
 and we're not really worried about what they're thinking about.

41
00:01:54,055 --> 00:01:56,330
 For novices though, it's very difficult for

42
00:01:56,330 --> 00:02:00,260
 the processor model to understand what a novice finds confusing or misleading.

43
00:02:00,260 --> 00:02:02,900
 Most generally, the processor model is usually

44
00:02:02,900 --> 00:02:05,630
 good for optimization but not for redesign.

45
00:02:05,630 --> 00:02:07,640
 If we're making small changes like the size of

46
00:02:07,640 --> 00:02:09,980
 buttons or the responsiveness of the screen,

47
00:02:09,980 --> 00:02:13,335
 then it can help us compare and understand which interface is performing better.

48
00:02:13,335 --> 00:02:16,685
 But if we're going to try a comprehensive new redesign,

49
00:02:16,685 --> 00:02:19,010
 the processor model isn't very helpful.

50
00:02:19,010 --> 00:02:22,510
 It might be good for evaluating that new redesign once we've created it,

51
00:02:22,510 --> 00:02:26,690
 but it doesn't give us very much input on what we should include in that redesign.

52
00:02:26,690 --> 00:02:29,065
 If we shift to the predictor model,

53
00:02:29,065 --> 00:02:32,075
 then we're going to actually start asking our users for input.

54
00:02:32,075 --> 00:02:33,680
 We could bring them in for interviews,

55
00:02:33,680 --> 00:02:36,550
 conduct focus groups, send out surveys.

56
00:02:36,550 --> 00:02:39,680
 We can also show them prototypes for new interfaces and

57
00:02:39,680 --> 00:02:42,780
 have them describe their thought process while trying to interact with them.

58
00:02:42,780 --> 00:02:46,640
 We might find some simple changes that we wouldn't have stumbled upon otherwise.

59
00:02:46,640 --> 00:02:48,530
 For example, we might find that users find

60
00:02:48,530 --> 00:02:51,695
 a certain icon to be misleading compared to its real meaning.

61
00:02:51,695 --> 00:02:53,990
 We might also find some information about why users

62
00:02:53,990 --> 00:02:56,525
 choose different interfaces at different times.

63
00:02:56,525 --> 00:02:58,910
 For example, users might prefer the voice interface while

64
00:02:58,910 --> 00:03:01,675
 driving but this text interface while they're parked.

65
00:03:01,675 --> 00:03:03,410
 So, the big advantage here is that we get

66
00:03:03,410 --> 00:03:07,265
 a more complete picture of the user's interaction with the interface.

67
00:03:07,265 --> 00:03:09,680
 We get to ask them why they do certain things,

68
00:03:09,680 --> 00:03:12,320
 or what they're thinking about, or why they made certain choices.

69
00:03:12,320 --> 00:03:16,405
 Additionally, this model lets us target different levels of expertise.

70
00:03:16,405 --> 00:03:18,380
 We can bring in novices who've never seen

71
00:03:18,380 --> 00:03:20,540
 the interface before and say, "Take a look at this.

72
00:03:20,540 --> 00:03:22,490
 What do you think you should do next?"

73
00:03:22,490 --> 00:03:26,210
 But we could also bring in experts and have them reflect on how some new interface

74
00:03:26,210 --> 00:03:30,050
 might make it more or less efficient to accomplish what they want to accomplish.

75
00:03:30,050 --> 00:03:31,895
 But again, there are drawbacks.

76
00:03:31,895 --> 00:03:35,734
 One big drawback is that the analysis of this can be very expensive.

77
00:03:35,734 --> 00:03:38,855
 We're not looking at numbers and conducting a little statistical tests.

78
00:03:38,855 --> 00:03:41,150
 We're often looking at plain text transcripts of

79
00:03:41,150 --> 00:03:44,164
 interviews or plain text responses to surveys.

80
00:03:44,164 --> 00:03:48,365
 Analyzing those requires a lot of human attention and a lot of effort.

81
00:03:48,365 --> 00:03:51,635
 Even then, that analysis can be subject to biases.

82
00:03:51,635 --> 00:03:53,750
 If the person analyzing that data has

83
00:03:53,750 --> 00:03:56,450
 some suspicions about what they think the better interface would be,

84
00:03:56,450 --> 00:03:59,360
 they're very likely to imbue their analysis with

85
00:03:59,360 --> 00:04:04,195
 those biases and only focus on data that confirms what they already think was true.

86
00:04:04,195 --> 00:04:07,280
 So, we have to make sure that they control for those biases.

87
00:04:07,280 --> 00:04:09,600
 Additionally, when we're using the predictor model,

88
00:04:09,600 --> 00:04:13,195
 we're still usually ignoring the broader interaction context.

89
00:04:13,195 --> 00:04:15,739
 We're usually looking at the person in the interface,

90
00:04:15,739 --> 00:04:20,090
 but not the real authentic environment in which they usually use that interface.

91
00:04:20,090 --> 00:04:22,850
 For this interface, that could be a problem because we might have an interface

92
00:04:22,850 --> 00:04:25,760
 that works very well when it has the full user attention.

93
00:04:25,760 --> 00:04:30,095
 But it's significantly harder to use when the user is, for instance, driving.

94
00:04:30,095 --> 00:04:33,680
 For example, if we were only testing a new interface in a lab setting,

95
00:04:33,680 --> 00:04:37,100
 we might have a feature that hides what the user has been searching for if

96
00:04:37,100 --> 00:04:40,790
 they haven't entered any new text or made a selection in the past five seconds.

97
00:04:40,790 --> 00:04:43,370
 In a lab setting, that's probably fine because our users are

98
00:04:43,370 --> 00:04:45,900
 generally only focused on the task that we're giving them,

99
00:04:45,900 --> 00:04:48,160
 which is entering some address into that search bar.

100
00:04:48,160 --> 00:04:49,890
 But if they're actually out driving,

101
00:04:49,890 --> 00:04:52,355
 they might start entering an address at one red light,

102
00:04:52,355 --> 00:04:54,140
 had light turn green and want to pause,

103
00:04:54,140 --> 00:04:56,390
 and continue entering it at the next red light.

104
00:04:56,390 --> 00:04:58,295
 If it disappears after five seconds,

105
00:04:58,295 --> 00:05:01,854
 that's not really aware of the way they're using it in the real environment.

106
00:05:01,854 --> 00:05:04,120
 So, that's where the participant model comes in.

107
00:05:04,120 --> 00:05:05,560
 With a participant model,

108
00:05:05,560 --> 00:05:10,655
 we view the interface and the user in the context in which they actually interact.

109
00:05:10,655 --> 00:05:15,530
 We want to look at the user in the interface as participants in some broader activity,

110
00:05:15,530 --> 00:05:17,405
 the broader activity of driving,

111
00:05:17,405 --> 00:05:20,119
 not just as a user interacting with one interface.

112
00:05:20,119 --> 00:05:22,290
 Now, the benefit of this should be pretty obvious.

113
00:05:22,290 --> 00:05:25,055
 It evaluates the interaction in context.

114
00:05:25,055 --> 00:05:28,160
 We can understand things like the driver is distracted or they're

115
00:05:28,160 --> 00:05:31,355
 going to do things in different batches as it come to different red lights.

116
00:05:31,355 --> 00:05:35,440
 We also capture an authentic representation of the user's level of attention.

117
00:05:35,440 --> 00:05:37,795
 If the user is going to be distracted, for example,

118
00:05:37,795 --> 00:05:40,130
 we'll see that when we analyze the activity

119
00:05:40,130 --> 00:05:42,700
 and the authentic contexts in which it takes place.

120
00:05:42,700 --> 00:05:45,620
 But unsurprisingly, there are also drawbacks to this approach to.

121
00:05:45,620 --> 00:05:50,285
 Just as the predictor model suggested evaluations that were difficult to analyze,

122
00:05:50,285 --> 00:05:55,250
 the participant model emphasizes evaluations that can actually be difficult to perform.

123
00:05:55,250 --> 00:05:58,440
 To evaluate this interface in the authentic contexts in which it's used,

124
00:05:58,440 --> 00:06:01,435
 we need to actually go right along with participants.

125
00:06:01,435 --> 00:06:03,920
 That's a lot harder to do than just sending out a survey

126
00:06:03,920 --> 00:06:06,790
 or bring people into our controlled lab environment.

127
00:06:06,790 --> 00:06:10,505
 It also means we need to have real functional interfaces.

128
00:06:10,505 --> 00:06:12,800
 We can't have a person driving a car and keep holding up

129
00:06:12,800 --> 00:06:15,530
 some prototype next to them while they're actually trying to drive.

130
00:06:15,530 --> 00:06:17,450
 We need these interfaces to actually be

131
00:06:17,450 --> 00:06:20,150
 designed and implemented to work in that real context.

132
00:06:20,150 --> 00:06:24,235
 So, it's hard to use this model when we're just getting started with a new design task.

133
00:06:24,235 --> 00:06:26,840
 Finally, using the participant model means that we're

134
00:06:26,840 --> 00:06:30,095
 exposing ourselves to a lot of uncontrollable variables.

135
00:06:30,095 --> 00:06:32,299
 The more that's going on in the environment,

136
00:06:32,299 --> 00:06:36,560
 the harder it is to zoom in and focus only on the impact of our designs.

137
00:06:36,560 --> 00:06:38,720
 Now, hopefully you'll notice that the pros of some

138
00:06:38,720 --> 00:06:41,045
 of these models address to cons of others.

139
00:06:41,045 --> 00:06:42,620
 The processor model, for example,

140
00:06:42,620 --> 00:06:45,130
 doesn't give us much insight into what novices are thinking.

141
00:06:45,130 --> 00:06:48,595
 But the predictor model is particularly good at targeting novices.

142
00:06:48,595 --> 00:06:52,480
 To predict a model makes it difficult to conduct real objective comparisons.

143
00:06:52,480 --> 00:06:54,915
 That's exactly what the processor model is good for.

144
00:06:54,915 --> 00:06:58,880
 Neither the processor nor the predictor model take into consideration context,

145
00:06:58,880 --> 00:07:01,240
 but that's what we get when we consider the participant model.

146
00:07:01,240 --> 00:07:03,170
 But it doesn't isolate variables very well.

147
00:07:03,170 --> 00:07:06,055
 It's subject to interference from things that we can't control.

148
00:07:06,055 --> 00:07:09,199
 But the processor model is very good at isolating those variables.

149
00:07:09,199 --> 00:07:11,945
 So the major takeaway here is it will likely use

150
00:07:11,945 --> 00:07:15,380
 all of these different models at different times and in different contexts.

151
00:07:15,380 --> 00:07:19,260
 The data we gather from one might inform what we do with another.

152
00:07:19,260 --> 00:07:21,500
 We might start with a participant model or we

153
00:07:21,500 --> 00:07:24,110
 just ride around with users watching what they do.

154
00:07:24,110 --> 00:07:26,570
 Based on that, we might observe that they spend a lot of time

155
00:07:26,570 --> 00:07:29,150
 fumbling around a return to the same few locations.

156
00:07:29,150 --> 00:07:32,045
 So, we might redesign an interface to include some kind of

157
00:07:32,045 --> 00:07:35,680
 bookmarking system and present it to users in interviews.

158
00:07:35,680 --> 00:07:38,670
 There, they might tell us they like that design,

159
00:07:38,670 --> 00:07:41,550
 but further note, they don't need a long list of bookmarks.

160
00:07:41,550 --> 00:07:43,805
 They really only need work and home.

161
00:07:43,805 --> 00:07:46,805
 So based on that, we might then design an interface where

162
00:07:46,805 --> 00:07:50,650
 a simple swipe takes him to work or to home depending on where they are right now.

163
00:07:50,650 --> 00:07:53,380
 In fact, that's how that Tesla navigation screen works.

164
00:07:53,380 --> 00:07:56,119
 If you just swipe across to navigate button,

165
00:07:56,119 --> 00:07:58,585
 it'll automatically take you to work if you're at home,

166
00:07:58,585 --> 00:08:00,120
 or home if you're at work.

167
00:08:00,120 --> 00:08:04,130
 Then, finally, we might test it with the processor model to see just how much

168
00:08:04,130 --> 00:08:08,410
 more efficiently that new interface allows users to put in their destination.

169
00:08:08,410 --> 00:08:11,235
 The results of each design phase inform the next,

170
00:08:11,235 --> 00:08:14,480
 and different phases call for different types of evaluation,

171
00:08:14,480 --> 00:08:14,480
 which echoed the different models of the user.

