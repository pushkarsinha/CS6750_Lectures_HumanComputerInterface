1
00:00:00,190 --> 00:00:03,660
 If you said yes, there are several reasons you might have stated.

2
00:00:03,660 --> 00:00:06,480
 You might agree that because the terms of service covered it,

3
00:00:06,480 --> 00:00:07,960
 it was technically ethical research.

4
00:00:07,960 --> 00:00:10,910
 The users did agree to things like this.

5
00:00:10,910 --> 00:00:14,170
 You may have actually read the article or read other publications about it and

6
00:00:14,170 --> 00:00:17,550
 noted that Facebook actually has an internal IRB that reviews things

7
00:00:17,550 --> 00:00:18,600
 like this.

8
00:00:18,600 --> 00:00:22,970
 And in this case, an external IRB did review the study.

9
00:00:22,970 --> 00:00:26,030
 If you said no, the reason you gave may have been that we know

10
00:00:26,030 --> 00:00:28,570
 users are not aware of what's in terms of use.

11
00:00:28,570 --> 00:00:31,707
 We have plenty of studies that indicate that users really don't spend any time

12
00:00:31,707 --> 00:00:33,930
 reading what they're agreeing to.

13
00:00:33,930 --> 00:00:37,236
 And while technically, it's true that they're still agreeing to it,

14
00:00:37,236 --> 00:00:40,370
 what we're interested in here are participants' rights.

15
00:00:40,370 --> 00:00:43,740
 If we know that users aren't reading what they're agreeing to,

16
00:00:43,740 --> 00:00:46,958
 don't we have an ethical obligation to make sure they're aware before we go

17
00:00:46,958 --> 00:00:47,840
 ahead with it.

18
00:00:47,840 --> 00:00:51,600
 We also might say no because users couldn't opt out of this study.

19
00:00:51,600 --> 00:00:54,710
 Part of that is because opting out of the study alone means deactivating your

20
00:00:54,710 --> 00:00:57,760
 entire Facebook account or just stopping using the tool.

21
00:00:57,760 --> 00:01:00,420
 But part of it is that users also weren't aware that a study was

22
00:01:00,420 --> 00:01:01,610
 now going on.

23
00:01:01,610 --> 00:01:04,370
 They couldn't opt out of the study specifically, nor

24
00:01:04,370 --> 00:01:07,230
 could they even opt out of it by closing down their entire Facebook account

25
00:01:07,230 --> 00:01:09,630
 because they didn't know when the study had started.

26
00:01:09,630 --> 00:01:11,020
 That ties into the other issue.

27
00:01:11,020 --> 00:01:13,910
 Users weren't notified that they were participants in an experiment.

28
00:01:13,910 --> 00:01:16,730
 So even though they technically agreed to it when they agreed to Facebook's

29
00:01:16,730 --> 00:01:20,100
 terms of service, one could argue the fact they weren't notified when

30
00:01:20,100 --> 00:01:23,400
 the study was beginning and ending means that it wasn't ethical research.

31
00:01:23,400 --> 00:01:25,420
 I'm not going to give you a right or wrong answer to this.

32
00:01:25,420 --> 00:01:28,410
 There's a very interesting conversation to have about this.

33
00:01:28,410 --> 00:01:32,000
 But what's most important here are the interesting questions that it brings up.

34
00:01:32,000 --> 00:01:35,780
 Especially in regard to companies doing human subjects research

35
00:01:35,780 --> 00:01:38,870
 that doesn't have any over sight from the federal government.

36
00:01:38,870 --> 00:01:41,560
 If you agreed with these reasons why it wasn't ethical,

37
00:01:41,560 --> 00:01:43,220
 what could they have done to fix it?

38
00:01:43,220 --> 00:01:45,600
 Maybe they could have separated out the consent process for

39
00:01:45,600 --> 00:01:48,870
 research studies from the rest of Facebook as a whole.

40
00:01:48,870 --> 00:01:52,460
 Maybe they could have specifically requested that individual users opt-in,

41
00:01:52,460 --> 00:01:54,360
 and alert them when the study was done, but

42
00:01:54,360 --> 00:01:56,780
 not tell them what's actually being manipulated.

43
00:01:56,780 --> 00:01:58,820
 And even if the original study was ethical,

44
00:01:58,820 --> 00:02:01,809
 there were likely things that could have reduced the backlash.

45
00:02:01,809 --> 00:02:05,530
 At the same time, those things might have affected the results.

46
00:02:05,530 --> 00:02:05,530
 These are the tradeoffs that we deal with.

